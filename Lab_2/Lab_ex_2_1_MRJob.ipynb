{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Lab_ex_2_1_MRJob.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
<<<<<<< Updated upstream
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_-d86u_XkJ"
      },
      "source": [
        "# Ex 2.1 Hadoop MapReduce with Python\n",
        "There are two prominent *Python* APIs for interfacing *Hadoop MapReduce* clusters:\n",
        "\n",
        "## *Snakebite* for *HDFS* access\n",
        "The [Snakebite Lib](https://github.com/spotify/snakebite) allows easy access to *HDFS* file systems:  \n",
        "```\n",
        ">>> from snakebite.client import Client\n",
        ">>> client = Client(\"localhost\", 8020, use_trash=False)\n",
        ">>> for x in client.ls(['/']):\n",
        "...     print x\n",
        "```\n",
        "\n",
        "See [documentation](https://snakebite.readthedocs.io/en/latest/) for details.\n",
        "\n",
        "\n",
        "## *MRJOB* for *MapReduce* job execution\n",
        "The ``mrjob`` lib -> [see docu](https://mrjob.readthedocs.io/en/latest/index.html) is a power full *MapReduce* client for *Python*. Some of the key features are:\n",
        "\n",
        "* local emulation (single and multi-core) a *Hadoop* cluster for development and debugging\n",
        "* simple access, authentication and file transfer to *Hadoop* clusters\n",
        "* powerful API for common cloud services, such as AWS or Azure   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdzU2hvc_XkN"
      },
      "source": [
        "### Preparing our environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftS_MV--_XkO",
        "outputId": "79b0e28c-30cb-46c4-896a-06c472d696cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#install mrjob lib and boto3 for AWS S3 access\n",
        "#!conda install -c conda-forge -y mrjob boto3\n",
        "\n",
        "!pip install mrjob boto3"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mrjob in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.17.87)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from mrjob) (3.13)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.87 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.20.87)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.4.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.87->boto3) (1.26.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.87->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.87->boto3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K48-ZIC_XkT"
      },
      "source": [
        "## A *MRJOB* Example: WordCount (again)\n",
        "Since *Hadoop* works only on file in- and outputs, we do not have usual function based API. We need to pass our code (implementation of *Map* and *Reduce*) as executable *Python* scripts:\n",
        "\n",
        "* use *Jupyter's* ``%%file`` magic command to write the cell to file\n",
        "* create a executable script with ``__main__`` method\n",
        "* inherit from the ``MRJob`` class\n",
        "* implement ``mapper()`` and ``reducer()`` methods\n",
        "* call ``run()`` at start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-gg4mlM_XkW",
        "outputId": "8f428996-0339-4464-fc23-b5637f42a3c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%file wordcount.py \n",
        "#this will save this cell as file\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "class MRWordCount(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        for word in line.split():\n",
        "            yield(word, 1)\n",
        " \n",
        "    def reducer(self, word, counts):\n",
        "        yield(word, sum(counts))\n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    MRWordCount.run()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting wordcount.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epIxdkI-_XkX"
      },
      "source": [
        "### execute script from cmd\n",
        "* ``-r local`` causes local multi-core emulation a *Hadoop* cluster.\n",
        "* Input files are cmd arguments\n",
        "* define ouput-file (see docs) or use streams: `` > out.txt``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_nUc0uje_XkX",
        "outputId": "a1e99bb1-a946-432a-e5a6-7c3c100561a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! python wordcount.py -r local *.rst > out.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for local runner\n",
            "Creating temp directory /tmp/wordcount.root.20210604.124659.188971\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/wordcount.root.20210604.124659.188971/output\n",
            "Streaming final output from /tmp/wordcount.root.20210604.124659.188971/output...\n",
            "Removing temp directory /tmp/wordcount.root.20210604.124659.188971...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kK20LbB_XkY"
      },
      "source": [
        " -> results in **out.txt** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZGeghhb_XkZ"
      },
      "source": [
        "## Execution on AWS EMR\n",
        "AWS EMR is a clound formation service which allows you to create *Hadoop*, *Spark* and other data analytics clusters with a few clicks.\n",
        "\n",
        "**NOTE**: we are not endorsing AWS specifically, other cloud service providers have similar offers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tuLu7xo_Xka"
      },
      "source": [
        "### Connect to existing cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnd6heQe_Xkb",
        "outputId": "1b828e9c-9dd9-4c0a-f5fa-ba6a976b183e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%file mrjob_cluster.conf\n",
        "runners:\n",
        "  emr:\n",
        "    aws_access_key_id: AKIA4KIF2TSEWQK7VOF4\n",
        "    aws_secret_access_key: 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\n",
        "    region: eu-west-1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mrjob_cluster.conf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p_AC9-G_Xkc"
      },
      "source": [
        "We need the **ID** of the cluster we want to connect to - here pre-set to our Cluster today"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDLbm7kz_Xkd"
      },
      "source": [
        "! python wordcount.py -r emr --cluster-id=j-L1BO0NYZIYY0 text1.rst text2.rst -c mrjob_cluster.conf  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUc3ArB9_Xke"
      },
      "source": [
        "## Exercise\n",
        "Use  *mrjob*  to  compute  employee  **top  annual  salaries** and  **gross pay** in the *CSV* table ``Baltimore_City_employee_Salaries_FY2014.csv``.\n",
        "\n",
        "* use  ``import csv`` to read the data -> [API docs](https://docs.python.org/3/library/csv.html)\n",
        "* use ``yield`` to return *producers* from *map* and *reduce* functions\n",
        "* return top entries in both categories "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM2C08V5_Xkf"
      },
      "source": [
        "import csv\n",
        "with open('Baltimore_City_Employee_Salaries_FY2014.csv', newline='') as csvfile:\n",
        "  reader = csv.DictReader(csvfile)\n",
        "  for row in reader:\n",
        "    print(row['AnnualSalary'], row['GrossPay'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W9-IGziF4Fk"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL28-NNGDxMu",
        "outputId": "7b7bff07-d99c-404c-cdfd-9df0874d20e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%file MRComputeSalaries.py \n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "cols = 'Name,JobTitle,AgencyID,Agency,HireDate,AnnualSalary,GrossPay'.split(',')\n",
        "\n",
        "class salarymax(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        # Convert each line into a dictionary\n",
        "        row = dict(zip(cols, [ a.strip() for a in next(csv.reader([line]))]))\n",
        "\n",
        "        # Yield the salary\n",
        "        try:\n",
        "          yield 'salary', (float(row['AnnualSalary']), line)\n",
        "        except ValueError:\n",
        "          self.increment_counter('warn', 'missing salary', 1)\n",
        "        \n",
        "        # Yield the gross pay\n",
        "        try:\n",
        "            yield 'gross', (float(row['GrossPay']), line)\n",
        "        except ValueError:\n",
        "            self.increment_counter('warn', 'missing gross', 1)\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        topten = []\n",
        "\n",
        "        # For 'salary' and 'gross' compute the top 10\n",
        "        for p in values:\n",
        "            topten.append(p)\n",
        "            topten.sort()\n",
        "            topten = topten[-10:]\n",
        "\n",
        "        for p in topten:\n",
        "            yield key, p\n",
        "\n",
        "    combiner = reducer\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    salarymax.run()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting MRComputeSalaries.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAUytFONEyH",
        "outputId": "906e4889-a54e-4e12-d998-e85906aac22f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python MRComputeSalaries.py -r local Baltimore_City_Employee_Salaries_FY2014.csv > top_salaries.txt\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for local runner\n",
            "Creating temp directory /tmp/MRComputeSalaries.root.20210604.141925.498227\n",
            "Running step 1 of 1...\n",
            "\n",
            "Counters: 2\n",
            "\twarn\n",
            "\t\tmissing gross=3224\n",
            "\t\tmissing salary=1\n",
            "\n",
            "job output is in /tmp/MRComputeSalaries.root.20210604.141925.498227/output\n",
            "Streaming final output from /tmp/MRComputeSalaries.root.20210604.141925.498227/output...\n",
            "Removing temp directory /tmp/MRComputeSalaries.root.20210604.141925.498227...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHF14eBZ-tX",
        "outputId": "0e4294a6-db0e-4465-a214-47be6022df20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! python  MRComputeSalaries.py -r emr --cluster-id=j-L1BO0NYZIYY0 Baltimore_City_Employee_Salaries_FY2014.csv -c mrjob_cluster.conf  > top_salaries2.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using s3://mrjob-42e7145df80ebe94/tmp/ as our temp dir on S3\n",
            "Creating temp directory /tmp/MRComputeSalaries.root.20210604.142351.359505\n",
            "uploading working dir files to s3://mrjob-42e7145df80ebe94/tmp/MRComputeSalaries.root.20210604.142351.359505/files/wd...\n",
            "Copying other local files to s3://mrjob-42e7145df80ebe94/tmp/MRComputeSalaries.root.20210604.142351.359505/files/\n",
            "Adding our job to existing cluster j-L1BO0NYZIYY0\n",
            "  master node is ec2-52-212-16-94.eu-west-1.compute.amazonaws.com\n",
            "Waiting for Step 1 of 1 (s-39HK2XAPQKEA8) to complete...\n",
            "  PENDING (cluster is RUNNING: Running step)\n",
            "  PENDING (cluster is RUNNING: Running step)\n",
            "  RUNNING for 0:00:59\n",
            "  COMPLETED\n",
            "Attempting to fetch counters from logs...\n",
            "Waiting 10 minutes for logs to transfer to S3... (ctrl-c to skip)\n",
            "\n",
            "To fetch logs immediately next time, set up SSH. See:\n",
            "https://pythonhosted.org/mrjob/guides/emr-quickstart.html#configuring-ssh-credentials\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
=======
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install mrjob lib and boto3 for AWS S3 access\n",
    "!conda install -c conda-forge -y mrjob boto3\n",
    "\n",
    "#!pip install mrjob boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A *MRJOB* Example: WordCount (again)\n",
    "Since *Hadoop* works only on file in- and outputs, we do not have usual function based API. We need to pass our code (implementation of *Map* and *Reduce*) as executable *Python* scripts:\n",
    "\n",
    "* use *Jupyter's* ``%%file`` magic command to write the cell to file\n",
    "* create a executable script with ``__main__`` method\n",
    "* inherit from the ``MRJob`` class\n",
    "* implement ``mapper()`` and ``reducer()`` methods\n",
    "* call ``run()`` at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcount.py \n",
    "#this will save this cell as file\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield(word, 1)\n",
    " \n",
    "    def reducer(self, word, counts):\n",
    "        yield(word, sum(counts))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRWordCount.run()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute script from cmd\n",
    "* ``-r local`` causes local multi-core emulation a *Hadoop* cluster.\n",
    "* Input files are cmd arguments\n",
    "* define ouput-file (see docs) or use streams: `` > out.txt``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/wordcount.keuper.20210604.123525.562975\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/wordcount.keuper.20210604.123525.562975/output\n",
      "Streaming final output from /tmp/wordcount.keuper.20210604.123525.562975/output...\n",
      "Removing temp directory /tmp/wordcount.keuper.20210604.123525.562975...\n"
     ]
    }
   ],
   "source": [
    "! python wordcount.py -r local *.rst > out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -> results in **out.txt** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution on AWS EMR\n",
    "AWS EMR is a clound formation service which allows you to create *Hadoop*, *Spark* and other data analytics clusters with a few clicks.\n",
    "\n",
    "**NOTE**: we are not endorsing AWS specifically, other cloud service providers have similar offers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to existing cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mrjob_cluster.conf\n"
     ]
    }
   ],
   "source": [
    "%%file mrjob_cluster.conf\n",
    "runners:\n",
    "  emr:\n",
    "    aws_access_key_id: AKIA4KIF2TSEYQPZZNG3\n",
    "    aws_secret_access_key: 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\n",
    "    region: eu-west-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the **ID** of the cluster we want to connect to - here pre-set to our Cluster today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using s3://mrjob-42e7145df80ebe94/tmp/ as our temp dir on S3\n",
      "Creating temp directory /tmp/wordcount.keuper.20210604.125218.449832\n",
      "uploading working dir files to s3://mrjob-42e7145df80ebe94/tmp/wordcount.keuper.20210604.125218.449832/files/wd...\n",
      "Copying other local files to s3://mrjob-42e7145df80ebe94/tmp/wordcount.keuper.20210604.125218.449832/files/\n",
      "Adding our job to existing cluster j-L1BO0NYZIYY0\n",
      "  master node is ec2-52-212-16-94.eu-west-1.compute.amazonaws.com\n",
      "Waiting for Step 1 of 1 (s-2FJWNFJ9WUZST) to complete...\n",
      "  PENDING (cluster is RUNNING: Running step)\n",
      "  RUNNING for 0:00:50\n",
      "  COMPLETED\n",
      "Attempting to fetch counters from logs...\n",
      "Waiting 10 minutes for logs to transfer to S3... (ctrl-c to skip)\n",
      "\n",
      "To fetch logs immediately next time, set up SSH. See:\n",
      "https://pythonhosted.org/mrjob/guides/emr-quickstart.html#configuring-ssh-credentials\n",
      "\n",
      "Looking for step log in s3://aws-logs-846657657993-eu-west-1/elasticmapreduce/j-L1BO0NYZIYY0/steps/s-2FJWNFJ9WUZST...\n",
      "  Parsing step log: s3://aws-logs-846657657993-eu-west-1/elasticmapreduce/j-L1BO0NYZIYY0/steps/s-2FJWNFJ9WUZST/syslog.gz\n",
      "Counters: 55\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=27487\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3958\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4887\n",
      "\t\tFILE: Number of bytes written=2700175\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1251\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=0\n",
      "\t\tS3: Number of bytes read=27487\n",
      "\t\tS3: Number of bytes written=3958\n",
      "\t\tS3: Number of large read operations=0\n",
      "\t\tS3: Number of read operations=0\n",
      "\t\tS3: Number of write operations=0\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=9\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=9\n",
      "\t\tLaunched reduce tasks=3\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=267479040\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=96964608\n",
      "\t\tTotal time spent by all map tasks (ms)=87070\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=8358720\n",
      "\t\tTotal time spent by all reduce tasks (ms)=15782\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3030144\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=87070\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=15782\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=19690\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=4133\n",
      "\t\tInput split bytes=1251\n",
      "\t\tMap input records=2\n",
      "\t\tMap output bytes=18952\n",
      "\t\tMap output materialized bytes=5681\n",
      "\t\tMap output records=1998\n",
      "\t\tMerged Map outputs=27\n",
      "\t\tPhysical memory (bytes) snapshot=7380963328\n",
      "\t\tReduce input groups=370\n",
      "\t\tReduce input records=1998\n",
      "\t\tReduce output records=370\n",
      "\t\tReduce shuffle bytes=5681\n",
      "\t\tShuffled Maps =27\n",
      "\t\tSpilled Records=3996\n",
      "\t\tTotal committed heap usage (bytes)=6949961728\n",
      "\t\tVirtual memory (bytes) snapshot=64040505344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in s3://mrjob-42e7145df80ebe94/tmp/wordcount.keuper.20210604.125218.449832/output/\n",
      "Streaming final output from s3://mrjob-42e7145df80ebe94/tmp/wordcount.keuper.20210604.125218.449832/output/...\n",
      "\"--\"\t6\n",
      "\"Alphabet\"\t3\n",
      "\"Blind\"\t9\n",
      "\"Bookmarksgrove\"\t4\n",
      "\"Consonantia,\"\t4\n",
      "\"Copy\"\t3\n",
      "\"God!\"\t3\n",
      "\"It\"\t4\n",
      "\"Longe\"\t3\n",
      "\"Marks\"\t3\n",
      "\"On\"\t3\n",
      "\"Separated\"\t4\n",
      "\"She\"\t3\n",
      "\"Village\"\t3\n",
      "\"Vokalia\"\t4\n",
      "\"When\"\t3\n",
      "\"When,\"\t3\n",
      "\"about\"\t3\n",
      "\"again\"\t3\n",
      "\"almost\"\t3\n",
      "\"ambushed\"\t3\n",
      "\"among\"\t6\n",
      "\"an\"\t6\n",
      "\"and,\"\t3\n",
      "\"are\"\t6\n",
      "\"at\"\t7\n",
      "\"belt\"\t3\n",
      "\"blind\"\t10\n",
      "\"buzz\"\t3\n",
      "\"by\"\t13\n",
      "\"cheek,\"\t3\n",
      "\"control\"\t3\n",
      "\"convince\"\t3\n",
      "\"countries\"\t4\n",
      "\"country,\"\t3\n",
      "\"day\"\t3\n",
      "\"devious\"\t3\n",
      "\"drunk\"\t3\n",
      "\"dwell\"\t3\n",
      "\"existence\"\t4\n",
      "\"eyes,\"\t3\n",
      "\"familiar\"\t3\n",
      "\"for\"\t13\n",
      "\"forms\"\t3\n",
      "\"friend,\"\t6\n",
      "\"full\"\t3\n",
      "\"gleams\"\t3\n",
      "\"grow\"\t3\n",
      "\"happy,\"\t3\n",
      "\"have\"\t3\n",
      "\"heart.\"\t4\n",
      "\"her,\"\t3\n",
      "\"herself\"\t3\n",
      "\"his\"\t3\n",
      "\"however\"\t3\n",
      "\"if\"\t3\n",
      "\"impenetrable\"\t3\n",
      "\"impress\"\t3\n",
      "\"indescribable\"\t3\n",
      "\"its\"\t9\n",
      "\"language\"\t4\n",
      "\"live\"\t8\n",
      "\"living\"\t3\n",
      "\"long\"\t3\n",
      "\"longing,\"\t3\n",
      "\"love\"\t3\n",
      "\"lovely\"\t3\n",
      "\"mountains,\"\t4\n",
      "\"mouth.\"\t3\n",
      "\"much\"\t3\n",
      "\"name\"\t3\n",
      "\"neglect\"\t3\n",
      "\"noticed\"\t3\n",
      "\"ocean.\"\t4\n",
      "\"of\"\t89\n",
      "\"over\"\t3\n",
      "\"own,\"\t3\n",
      "\"paper\"\t3\n",
      "\"paradisematic\"\t3\n",
      "\"parts\"\t3\n",
      "\"possession\"\t4\n",
      "\"projects\"\t3\n",
      "\"put\"\t3\n",
      "\"ran\"\t3\n",
      "\"regelialia.\"\t4\n",
      "\"rewritten,\"\t3\n",
      "\"right\"\t4\n",
      "\"roasted\"\t3\n",
      "\"said\"\t3\n",
      "\"sanctuary,\"\t3\n",
      "\"seem\"\t3\n",
      "\"sense\"\t3\n",
      "\"serenity\"\t4\n",
      "\"seven\"\t3\n",
      "\"should\"\t6\n",
      "\"skyline\"\t3\n",
      "\"so,\"\t3\n",
      "\"souls\"\t4\n",
      "\"splendour\"\t3\n",
      "\"stray\"\t3\n",
      "\"stroke\"\t3\n",
      "\"subline\"\t3\n",
      "\"sun\"\t3\n",
      "\"supplies\"\t4\n",
      "\"surface\"\t3\n",
      "\"sustains\"\t3\n",
      "\"talents.\"\t3\n",
      "\"tall\"\t3\n",
      "\"teems\"\t3\n",
      "\"text\"\t3\n",
      "\"the\"\t155\n",
      "\"there\"\t7\n",
      "\"think\"\t3\n",
      "\"thousands\"\t3\n",
      "\"trees,\"\t3\n",
      "\"under\"\t3\n",
      "\"upon\"\t3\n",
      "\"us,\"\t3\n",
      "\"vapour\"\t3\n",
      "\"warned\"\t3\n",
      "\"were\"\t3\n",
      "\"where\"\t6\n",
      "\"wild\"\t3\n",
      "\"with\"\t20\n",
      "\"within\"\t3\n",
      "\"wonderful\"\t4\n",
      "\"word\"\t7\n",
      "\"Almighty,\"\t3\n",
      "\"Big\"\t3\n",
      "\"Bookmarksgrove,\"\t3\n",
      "\"Commas,\"\t3\n",
      "\"Duden\"\t4\n",
      "\"Grammar.\"\t3\n",
      "\"I\"\t44\n",
      "\"Ipsum\"\t3\n",
      "\"Italic\"\t3\n",
      "\"Lane.\"\t3\n",
      "\"Lorem\"\t3\n",
      "\"O\"\t3\n",
      "\"Pityful\"\t3\n",
      "\"Semantics,\"\t4\n",
      "\"Semikoli,\"\t3\n",
      "\"Text\"\t6\n",
      "\"Text,\"\t3\n",
      "\"The\"\t6\n",
      "\"Writers\"\t3\n",
      "\"\\\"and\\\"\"\t3\n",
      "\"\\u001b[200~Far\"\t1\n",
      "\"a\"\t40\n",
      "\"absorb\"\t3\n",
      "\"absorbed\"\t3\n",
      "\"again.\"\t3\n",
      "\"all\"\t3\n",
      "\"all-powerful\"\t3\n",
      "\"and\"\t78\n",
      "\"artist\"\t3\n",
      "\"bad\"\t3\n",
      "\"be\"\t9\n",
      "\"bears\"\t3\n",
      "\"because\"\t3\n",
      "\"behind\"\t4\n",
      "\"bliss;\"\t3\n",
      "\"breath\"\t3\n",
      "\"but\"\t9\n",
      "\"came\"\t3\n",
      "\"close\"\t3\n",
      "\"conceptions,\"\t3\n",
      "\"continued\"\t3\n",
      "\"copy.\"\t3\n",
      "\"countless\"\t3\n",
      "\"darkness\"\t3\n",
      "\"dear\"\t3\n",
      "\"didn\\u2019t\"\t6\n",
      "\"do\"\t3\n",
      "\"dragged\"\t3\n",
      "\"drawing\"\t3\n",
      "\"enjoy\"\t4\n",
      "\"eternity\"\t3\n",
      "\"far\"\t11\n",
      "\"feel\"\t10\n",
      "\"few\"\t6\n",
      "\"first\"\t3\n",
      "\"floats\"\t3\n",
      "\"flows\"\t4\n",
      "\"fly\"\t3\n",
      "\"form\"\t3\n",
      "\"formed\"\t3\n",
      "\"from\"\t10\n",
      "\"had\"\t3\n",
      "\"has\"\t7\n",
      "\"headline\"\t3\n",
      "\"her\"\t36\n",
      "\"hills\"\t3\n",
      "\"hometown\"\t3\n",
      "\"incapable\"\t3\n",
      "\"infinite\"\t3\n",
      "\"inner\"\t3\n",
      "\"insidious\"\t3\n",
      "\"into\"\t12\n",
      "\"is\"\t15\n",
      "\"last\"\t3\n",
      "\"leave\"\t3\n",
      "\"left\"\t3\n",
      "\"like\"\t10\n",
      "\"line\"\t3\n",
      "\"me:\"\t3\n",
      "\"might\"\t3\n",
      "\"mine.\"\t3\n",
      "\"mirror\"\t6\n",
      "\"not\"\t3\n",
      "\"often\"\t3\n",
      "\"origin\"\t3\n",
      "\"own\"\t6\n",
      "\"rewritten\"\t3\n",
      "\"river\"\t4\n",
      "\"safe\"\t3\n",
      "\"small\"\t7\n",
      "\"so\"\t12\n",
      "\"soul\"\t6\n",
      "\"soul,\"\t7\n",
      "\"spot,\"\t4\n",
      "\"spring\"\t4\n",
      "\"stalks,\"\t3\n",
      "\"steal\"\t3\n",
      "\"still\"\t3\n",
      "\"strikes\"\t3\n",
      "\"sweet\"\t4\n",
      "\"take\"\t3\n",
      "\"taken\"\t4\n",
      "\"than\"\t3\n",
      "\"that\"\t21\n",
      "\"their\"\t10\n",
      "\"these\"\t10\n",
      "\"they\"\t10\n",
      "\"throw\"\t3\n",
      "\"times\"\t3\n",
      "\"turn\"\t3\n",
      "\"us\"\t6\n",
      "\"warm\"\t3\n",
      "\"was\"\t10\n",
      "\"way\"\t3\n",
      "\"weight\"\t3\n",
      "\"which\"\t14\n",
      "\"while\"\t3\n",
      "\"who\"\t3\n",
      "\"whole\"\t4\n",
      "\"world\"\t3\n",
      "\"would\"\t9\n",
      "\"your\"\t3\n",
      "\"A\"\t7\n",
      "\"And\"\t3\n",
      "\"But\"\t3\n",
      "\"Even\"\t3\n",
      "\"Far\"\t2\n",
      "\"Line\"\t3\n",
      "\"Little\"\t9\n",
      "\"Mountains,\"\t3\n",
      "\"Oh,\"\t3\n",
      "\"One\"\t3\n",
      "\"Oxmox\"\t3\n",
      "\"Parole\"\t3\n",
      "\"Pointing\"\t3\n",
      "\"Question\"\t3\n",
      "\"World\"\t3\n",
      "\"abused\"\t3\n",
      "\"advised\"\t3\n",
      "\"agency,\"\t3\n",
      "\"alone,\"\t4\n",
      "\"am\"\t7\n",
      "\"around\"\t9\n",
      "\"as\"\t9\n",
      "\"away,\"\t4\n",
      "\"back\"\t3\n",
      "\"been\"\t6\n",
      "\"beloved\"\t3\n",
      "\"bliss\"\t4\n",
      "\"charm\"\t4\n",
      "\"coast\"\t4\n",
      "\"copy\"\t6\n",
      "\"could\"\t9\n",
      "\"country.\"\t3\n",
      "\"created\"\t4\n",
      "\"decided\"\t3\n",
      "\"describe\"\t3\n",
      "\"down\"\t3\n",
      "\"earth\"\t3\n",
      "\"earth,\"\t3\n",
      "\"entire\"\t4\n",
      "\"everything\"\t3\n",
      "\"existence,\"\t3\n",
      "\"exquisite\"\t3\n",
      "\"flies,\"\t3\n",
      "\"foliage\"\t3\n",
      "\"friend\"\t3\n",
      "\"grass\"\t3\n",
      "\"greater\"\t3\n",
      "\"hasn\\u2019t\"\t3\n",
      "\"hear\"\t3\n",
      "\"heaven\"\t3\n",
      "\"her.\"\t2\n",
      "\"her.Far\"\t1\n",
      "\"image,\"\t3\n",
      "\"in\"\t23\n",
      "\"initial\"\t3\n",
      "\"insects\"\t3\n",
      "\"it\"\t25\n",
      "\"large\"\t4\n",
      "\"lie\"\t3\n",
      "\"life\"\t3\n",
      "\"listen.\"\t3\n",
      "\"little\"\t3\n",
      "\"made\"\t6\n",
      "\"me,\"\t6\n",
      "\"mere\"\t3\n",
      "\"meridian\"\t3\n",
      "\"met\"\t3\n",
      "\"mistress,\"\t3\n",
      "\"moment;\"\t3\n",
      "\"mornings\"\t4\n",
      "\"my\"\t38\n",
      "\"myself\"\t3\n",
      "\"named\"\t4\n",
      "\"necessary\"\t4\n",
      "\"never\"\t3\n",
      "\"no\"\t3\n",
      "\"nothing\"\t3\n",
      "\"now.\"\t3\n",
      "\"on\"\t6\n",
      "\"overspreads\"\t3\n",
      "\"packed\"\t3\n",
      "\"place\"\t4\n",
      "\"plants\"\t3\n",
      "\"power,\"\t3\n",
      "\"presence\"\t3\n",
      "\"present\"\t3\n",
      "\"question\"\t3\n",
      "\"reached\"\t3\n",
      "\"rethoric\"\t3\n",
      "\"return\"\t3\n",
      "\"road,\"\t3\n",
      "\"sentences\"\t3\n",
      "\"she\"\t15\n",
      "\"single\"\t3\n",
      "\"sink\"\t3\n",
      "\"stream;\"\t3\n",
      "\"strength\"\t3\n",
      "\"texts\"\t3\n",
      "\"texts.\"\t4\n",
      "\"then\"\t12\n",
      "\"then,\"\t3\n",
      "\"this\"\t4\n",
      "\"thousand\"\t6\n",
      "\"to\"\t15\n",
      "\"too\"\t3\n",
      "\"tranquil\"\t3\n",
      "\"trickling\"\t3\n",
      "\"universal\"\t3\n",
      "\"unknown\"\t3\n",
      "\"unorthographic\"\t3\n",
      "\"until\"\t3\n",
      "\"upper\"\t3\n",
      "\"using\"\t3\n",
      "\"valley\"\t3\n",
      "\"versalia,\"\t3\n",
      "\"view\"\t3\n",
      "\"visions!\"\t2\n",
      "\"visions!A\"\t1\n",
      "\"way.\"\t6\n",
      "\"when\"\t6\n",
      "\"yet\"\t3\n",
      "Removing s3 temp directory s3://mrjob-42e7145df80ebe94/tmp/wordcount.keuper.20210604.125218.449832/...\n",
      "Removing temp directory /tmp/wordcount.keuper.20210604.125218.449832...\n"
     ]
    }
   ],
   "source": [
    "! python wordcount.py -r emr --cluster-id=j-L1BO0NYZIYY0 text1.rst text2.rst -c mrjob_cluster.conf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Use  *mrjob*  to  compute  employee  **top  annual  salaries** and  **gross pay** in the *CSV* table ``Baltimore_City_employee_Salaries_FY2014.csv``.\n",
    "\n",
    "* use  ``import csv`` to read the data -> [API docs](https://docs.python.org/3/library/csv.html)\n",
    "* use ``yield`` to return *producers* from *map* and *reduce* functions\n",
    "* return top entries in both categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Baltimore_City_Employee_Salaries_FY2014.csv', newline='') as csvfile:\n",
    "  reader = csv.DictReader(csvfile)\n",
    "  for row in reader:\n",
    "    print(row['AnnualSalary'], row['GrossPay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file MRComputeSalaries.py \n",
    "#this will save this cell as file\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRComputeSalaries(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield(word, 1)\n",
    " \n",
    "    def reducer(self, word, counts):\n",
    "        yield(word, sum(counts))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRComputeSalariest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> Stashed changes
